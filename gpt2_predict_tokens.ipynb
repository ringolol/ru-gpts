{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel, AutoModelWithLMHead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"sberbank-ai/rugpt3large_based_on_gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelWithLMHead.from_pretrained(\"sberbank-ai/rugpt3large_based_on_gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode context the generation is conditioned on\n",
    "input_ids = tokenizer.encode('Я люблю гулять со своей собакой', return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_token(s, n=5, l=1, top_k=0, top_p=1., temperature=1.):\n",
    "    # encode context the generation is conditioned on\n",
    "    input_ids = tokenizer.encode(s, return_tensors='pt')\n",
    "    # activate beam search and early_stopping\n",
    "    beam_outputs = model.generate(\n",
    "        input_ids,  \n",
    "        max_length=input_ids.shape[1]+l, \n",
    "#         num_beams=n, \n",
    "        early_stopping=True,\n",
    "        do_sample=True,\n",
    "        num_return_sequences=n,\n",
    "        top_k=top_k,\n",
    "        top_p=top_p,\n",
    "        temperature=temperature\n",
    "    ).to('cuda')\n",
    "\n",
    "    # now we have 3 output sequences\n",
    "    print(f\"{s}:\\n\" + 100 * '-')\n",
    "    for i, beam_output in enumerate(beam_outputs):\n",
    "      print(\"{}: {}\".format(i, tokenizer.decode(beam_output, skip_special_tokens=True)[len(s):]).strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\utils\\checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Я люблю:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "0: ' тебя'\n",
      "1: ','\n",
      "2: ' вас'\n",
      "3: ' свою'\n",
      "4: ' его'\n"
     ]
    }
   ],
   "source": [
    "predict_token('Я люблю')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Я хочу:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "0: ','\n",
      "1: ' сказать'\n",
      "2: ' быть'\n",
      "3: ' знать'\n",
      "4: ' жить'\n"
     ]
    }
   ],
   "source": [
    "predict_token('Я хочу')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Он:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "0: ' был'\n",
      "1: ' не'\n",
      "2: ' сказал'\n",
      "3: ','\n",
      "4: ' уже'\n"
     ]
    }
   ],
   "source": [
    "predict_token('Он')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "0: ','\n",
      "1: '!'\n",
      "2: ' World'\n",
      "3: '\\n'\n",
      "4: ' world'\n"
     ]
    }
   ],
   "source": [
    "predict_token('Hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Я хочу:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "0: ', чтобы ты была счастлива.\\n\\n—\\xa0Я счастлива.\\n\\n—\\xa0Я хочу, чтобы ты была счастлива.\\n\\n—\\xa0Я счастлива.\\n\\n—\\xa0Я хочу, чтобы ты была счастлива.\\n\\n—\\xa0Я счастлива'\n",
      "1: ', чтобы ты была счастлива.\\n\\n–\\xa0Я счастлива.\\n\\n–\\xa0Я хочу, чтобы ты была счастлива.\\n\\n–\\xa0Я счастлива.\\n\\n–\\xa0Я хочу, чтобы ты была счастлива.\\n\\n–\\xa0Я счастлива'\n",
      "2: ', чтобы ты была счастлива.\\n\\n—\\xa0Я счастлива.\\n\\n—\\xa0Я хочу, чтобы ты была счастлива.\\n\\n—\\xa0Я счастлива.\\n\\n—\\xa0Я хочу, чтобы ты была счастлива.\\n\\n—\\xa0Я…'\n",
      "3: ', чтобы ты была счастлива.\\n\\n—\\xa0Я счастлива.\\n\\n—\\xa0Я хочу, чтобы ты была счастлива.\\n\\n—\\xa0Я счастлива.\\n\\n—\\xa0Я хочу, чтобы ты была счастлива.\\n\\n—\\xa0Я хочу'\n",
      "4: ', чтобы ты была счастлива.\\n\\n–\\xa0Я счастлива.\\n\\n–\\xa0Я хочу, чтобы ты была счастлива.\\n\\n–\\xa0Я счастлива.\\n\\n–\\xa0Я хочу, чтобы ты была счастлива.\\n\\n–\\xa0Я…'\n"
     ]
    }
   ],
   "source": [
    "predict_token('Я хочу', l=50, top_k=10, top_p=0.95) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вечерело. Проходя мимо старого засаленого кабака я вдруг:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "0:  поймал себя на мысли, что я не хочу выпить в этом захолустье, и это желание почему-то мне понравилось.\n",
      "\n",
      "Проходя мимо какого-то грязного здания я остановился и подумал, что неплохо было бы помыться, как вдруг\n",
      "1:  услышал скрип калитки, и увидел на ней силуэт. Это была женщина. Я быстро завернул за угол и увидел ее. Женщина была босая и в одной рубашке. Я увидел, как она сняла с головы свою соломенную шляпу, отбросила ее\n",
      "2:  вспомнил:\n",
      "- Ребята, а у Вас ничего не найдется выпить?\n",
      "В ответ мне был гробовой взгляд.\n",
      "Я тогда понял, что мне и здесь не рады.\n",
      "В этот момент в кабаке появились люди в чёрных плащах.\n",
      "3:  заметил, что в окне зажигается свет и кто-то выходит на улицу. Вскочив на свой велосипед я помчался на свет и через пару минут увидел того самого бродягу, который вышел за мной. Я его окликнул, но тот не обратил на меня\n",
      "4:  ощутил, что в моем нутре что-то дрогнуло. Я остановился, посмотрел под ноги и не увидел там ничего.\n",
      "\n",
      "В это время по улице проехала карета с гербом Российской Империи, и я снова понял, что что\n"
     ]
    }
   ],
   "source": [
    "predict_token('Вечерело. Проходя мимо старого засаленого кабака я вдруг', l=50, top_k=50, top_p=0.95, n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вечерело. Проходя мимо старого засаленого кабака я вдруг:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "0:  подумал: «А может это тот самый? Надо бы наведаться. Только сегодня как-то не хочется, а вдруг это тот самый? Я ведь так ничего о нем не знаю. Хотя, чего это я все о нем? Да и к чему\n",
      "1:  заметил двух проституток, они курили одну сигарету. Одна из них была явно с улицы и в платье, как у шлюхи. Я не мог не подойти, познакомиться, но она сделала мне знак молчать. И я стоял молча, разглядывая ее платье\n",
      "2:  увидел, что на дверях стоит объявление, извещающее о закрытии, да еще и с указанием времени.\n",
      "- Блин, ну неееет… - протянул я и полез в карман за мелочью.\n",
      "- Деньги есть?\n",
      "Я с\n",
      "3:  остановился, и не просто остановился, а замер.\n",
      "\n",
      "Там, за стойкой, кто-то сидел и пил. Я заглянул за стойку и замер от ужаса:\n",
      "\n",
      "— Сюда нельзя, не смотри, — сказала Оля.\n",
      "4:  остановился, будто налетел на стену, и долго пытался вспомнить, где же я видел его. В тот момент, когда я уже хотел было уйти, меня будто кто-то позвал и я оглянулся. Передо мной стоял тот самый незнакомец, который на\n"
     ]
    }
   ],
   "source": [
    "predict_token('Вечерело. Проходя мимо старого засаленого кабака я вдруг', l=50, top_k=50, top_p=0.90, n=5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
